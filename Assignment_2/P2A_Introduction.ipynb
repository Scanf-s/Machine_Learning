{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihiU8Q_I8w8t"
      },
      "source": [
        "# Assignment 2\n",
        "## Part 2A Introduction: Multi-label Image Classification (30 pts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x ./download_data.sh\n",
        "! ./download_data.sh"
      ],
      "metadata": {
        "id": "70m2G6ac_OSv",
        "outputId": "53fce99b-d212-4329-8c71-aee330a1661a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-13 14:13:55--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  20.6MB/s    in 20s     \n",
            "\n",
            "2025-05-13 14:14:15 (22.0 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "--2025-05-13 14:14:16--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M  21.8MB/s    in 20s     \n",
            "\n",
            "2025-05-13 14:14:37 (21.4 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F5LKhoax8w8u",
        "outputId": "2f280fe1-4dd8-4684-e9fb-c79ca21ec0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import average_precision_score\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from submission import output_submission_csv\n",
        "from classifier import SimpleClassifier, Classifier#, AlexNet\n",
        "from voc_dataloader import VocDataset, VOC_CLASSES\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYHrISFP8w8v"
      },
      "source": [
        "# Multi-label Classification\n",
        "In this assignment, you train a classifier to do multi-label classificaton on the PASCAL VOC 2007 dataset. The dataset has 20 different class which can appear in any given image. Your classifier will predict whether each class appears in an image. This task is slightly different from exclusive multiclass classification like the ImageNet competition where only a single most appropriate class is predicted for an image.\n",
        "\n",
        "## Part 2A\n",
        "You will use this notebook to warm up with pytorch and the code+dataset that we will use for assignment2.\n",
        "\n",
        "### What to do\n",
        "In part 2A, You are asked to run below experiments. You don't need to change hyperparameters for this Part 2A's experiments. (the following code provides everything that you will need.)\n",
        "1. to train a simple network (defined in ```classifiers.py```)\n",
        "2. to train the AlexNet (PyTorch built-in)\n",
        "    - from scratch\n",
        "    - finetuning AlexNet pretrained on ImageNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4KlsLbQ8w8v"
      },
      "source": [
        "## Reading Pascal Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q91T8mrL8w8v"
      },
      "source": [
        "### Loading Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fENXxzoT8w8v"
      },
      "source": [
        "In the following cell we will load the training data and also apply some transforms to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RD3Mc8b48w8v"
      },
      "outputs": [],
      "source": [
        "# Transforms applied to the training data\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std= [0.229, 0.224, 0.225])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_6GT7z518w8v",
        "outputId": "ebc00bba-27b8-4af8-dea6-cdc6f1032257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2501,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-07bcd6d2bd92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VOCdevkit_2007/VOC2007/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/voc_dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, dataset_split, transform, random_crops)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         ) = self.__dataset_info()\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/voc_dataloader.py\u001b[0m in \u001b[0;36m__dataset_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mlabel_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2501,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "ds_train = VocDataset('VOCdevkit_2007/VOC2007/','train',train_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HeeY8gN8w8v"
      },
      "source": [
        "### Loading Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZTpnP-18w8v"
      },
      "source": [
        "We will load the test data for the PASCAL VOC 2007 dataset. Do __NOT__ add data augmentation transforms to validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsvHu4Hv8w8v"
      },
      "outputs": [],
      "source": [
        "# Transforms applied to the testing data\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqYYnSzj8w8w"
      },
      "outputs": [],
      "source": [
        "ds_val = VocDataset('VOCdevkit_2007/VOC2007/','val',test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-9Hc9gl8w8w"
      },
      "source": [
        "### Visualizing the Data\n",
        "\n",
        "PASCAL VOC has bounding box annotations in addition to class labels. Use the following code to visualize some random examples and corresponding annotations from the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpnY4ZOW8w8w"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    idx = np.random.randint(0, len(ds_train.names)+1)\n",
        "    _imgpath = os.path.join('VOCdevkit_2007/VOC2007/', 'JPEGImages', ds_train.names[idx]+'.jpg')\n",
        "    img = Image.open(_imgpath).convert('RGB')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for j in range(len(ds_train.box_indices[idx])):\n",
        "        obj = ds_train.box_indices[idx][j]\n",
        "        draw.rectangle(list(obj), outline=(255,0,0))\n",
        "        draw.text(list(obj[0:2]), ds_train.classes[ds_train.label_order[idx][j]], fill=(0,255,0))\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.imshow(np.array(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIki1yBg8w8w"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCnrbA838w8w"
      },
      "outputs": [],
      "source": [
        "# declare what device to use: gpu/cpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aO3UpP_8w8w"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
        "                                               batch_size=50,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiOa5l-x8w8w"
      },
      "outputs": [],
      "source": [
        "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
        "                                               batch_size=50,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz6Si6ib8w8w"
      },
      "outputs": [],
      "source": [
        "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
        "    classifier.train()\n",
        "    loss_ = 0.0\n",
        "    losses = []\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = classifier(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "    return torch.stack(losses).mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXLtSC8_8w8w"
      },
      "outputs": [],
      "source": [
        "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n",
        "    classifier.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        y_true = np.zeros((0,21))\n",
        "        y_score = np.zeros((0,21))\n",
        "        for i, (images, labels) in enumerate(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = classifier(images)\n",
        "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
        "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
        "            loss = criterion(logits, labels)\n",
        "            losses.append(loss.item())\n",
        "        aps = []\n",
        "        # ignore first class which is background\n",
        "        for i in range(1, y_true.shape[1]):\n",
        "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
        "            if print_ind_classes:\n",
        "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
        "            aps.append(ap)\n",
        "\n",
        "        mAP = np.mean(aps)\n",
        "        test_loss = np.mean(losses)\n",
        "        if print_total:\n",
        "            print('mAP: {0:.4f}'.format(mAP))\n",
        "            print('Avg loss: {}'.format(test_loss))\n",
        "\n",
        "    return mAP, test_loss, aps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyuzTIRO8w8w"
      },
      "outputs": [],
      "source": [
        "# plot functions\n",
        "def plot_losses(train, val, test_frequency, num_epochs):\n",
        "    plt.plot(train, label=\"train\")\n",
        "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
        "    plt.plot(indices, val, label=\"val\")\n",
        "    plt.title(\"Loss Plot\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_mAP(train, val, test_frequency, num_epochs):\n",
        "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
        "    plt.plot(indices, train, label=\"train\")\n",
        "    plt.plot(indices, val, label=\"val\")\n",
        "    plt.title(\"mAP Plot\")\n",
        "    plt.ylabel(\"mAP\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFqK57MW8w8w"
      },
      "source": [
        "## Training the network\n",
        "\n",
        "The simple network you are given as is will allow you to reach around 0.15-0.2 mAP. In this project, you will find ways to design a better network. Save plots and final test mAP scores as you will be adding these to the writeup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpdUM1ii8w8w"
      },
      "outputs": [],
      "source": [
        "def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n",
        "    train_losses = []\n",
        "    train_mAPs = []\n",
        "    val_losses = []\n",
        "    val_mAPs = []\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        print(\"Starting epoch number \" + str(epoch))\n",
        "        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
        "        train_losses.append(train_loss)\n",
        "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
        "        if(epoch%test_frequency==0 or epoch==1):\n",
        "            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n",
        "            train_mAPs.append(mAP_train)\n",
        "            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
        "            print('Evaluating classifier')\n",
        "            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
        "            val_losses.append(val_loss)\n",
        "            val_mAPs.append(mAP_val)\n",
        "\n",
        "    return classifier, train_losses, val_losses, train_mAPs, val_mAPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdDD9JMY8w8x"
      },
      "outputs": [],
      "source": [
        "classifier = SimpleClassifier().to(device)\n",
        "# You can can use this function to reload a network you have already saved previously\n",
        "#classifier.load_state_dict(torch.load('voc_classifier.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar3IHIuO8w8x"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CJ1RNBrQ8w8x"
      },
      "outputs": [],
      "source": [
        "# Training the Classifier\n",
        "num_epochs = 20\n",
        "test_frequency = 5\n",
        "\n",
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtWypMGe8w8x"
      },
      "outputs": [],
      "source": [
        "# Compare train and validation metrics\n",
        "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
        "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9diiZuP8w8x"
      },
      "outputs": [],
      "source": [
        "# Save the clssifier network\n",
        "# Suggestion: you can save checkpoints of your network during training and reload them later\n",
        "torch.save(classifier.state_dict(), './voc_simple_classifier.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2VZ5G7U8w8x"
      },
      "source": [
        "# Evaluate on test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ac-P88L8w8x"
      },
      "outputs": [],
      "source": [
        "ds_test = VocDataset('VOCdevkit_2007/VOC2007test/','test', test_transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
        "                                               batch_size=50,\n",
        "                                               shuffle=False,\n",
        "                                               num_workers=1)\n",
        "\n",
        "# Transforms applied to the testing data\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(227),\n",
        "            transforms.CenterCrop(227),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6c9l94h8w8x"
      },
      "outputs": [],
      "source": [
        "output_submission_csv('simplemodel.csv', test_aps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWeY3eIH8w8x"
      },
      "source": [
        "# AlexNet Baselines (From Scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mlU9NTA8w8x"
      },
      "source": [
        "AlexNet was one of the earliest deep learning models to have success in classification. In this section we will be running classification with AlexNet as a baseline. Furthermore, we will run an ImageNet-pretrained AlexNet to observe the impact of well-trained features. Save plots and final test mAP scores as you will be adding these to the writeup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVVQFlZ8w8x"
      },
      "source": [
        "## Running AlexNet\n",
        "\n",
        "In this section, we train AlexNet from scratch using the same hyperparameters as our previous experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IqpQMH8J8w8x"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "test_frequency = 5\n",
        "\n",
        "# Change classifier to AlexNet\n",
        "classifier = torchvision.models.alexnet(pretrained=False)\n",
        "classifier.classifier._modules['6'] = nn.Linear(4096, 21)\n",
        "classifier = classifier.to(device)\n",
        "\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2o6in908w8x"
      },
      "outputs": [],
      "source": [
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj7ODgpb8w8x"
      },
      "outputs": [],
      "source": [
        "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
        "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emRwaDVh8w8y"
      },
      "outputs": [],
      "source": [
        "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
        "print(\"Test mAP: \", mAP_test)\n",
        "output_submission_csv('fromscratch.csv', test_aps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojEontMU8w8y"
      },
      "source": [
        "You should notice somewhat poor performance. You could try running AlexNet with an Adam optimizer instead with learning rate 1e-4 to see if that makes a difference. This experiment is not required for the writeup, but it may show you the importance of a good learning rate and optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCOMmk1P8w8y"
      },
      "source": [
        "## Pretrained AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HLYrox8w8y"
      },
      "source": [
        "Here we look at the impact of pretrained features. This model's weights were trained on ImageNet, which is a much larger dataset. How do pretrained features perform on VOC? Why do you think there is such a large difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf1a_Ksq8w8y"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "test_frequency = 5\n",
        "\n",
        "# Load Pretrained AlexNet\n",
        "classifier = torchvision.models.alexnet(pretrained=True)\n",
        "classifier.classifier._modules['6'] = nn.Linear(4096, 21)\n",
        "classifier = classifier.to(device)\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nzzfPqP8w8y"
      },
      "outputs": [],
      "source": [
        "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7y7JyFw8w8y"
      },
      "outputs": [],
      "source": [
        "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
        "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flpyxw3Y8w8y"
      },
      "outputs": [],
      "source": [
        "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
        "print(\"Test mAP: \", mAP_test)\n",
        "output_submission_csv('pretrained.csv', test_aps)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deyo_env",
      "language": "python",
      "name": "deyo_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}